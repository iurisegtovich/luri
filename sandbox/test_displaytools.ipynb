{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py running\n",
      "it' s not very effective\n",
      "xxx1 load ext entry point\n"
     ]
    }
   ],
   "source": [
    "%load_ext luri.luri_displaytools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "import tokenize\n",
    "import token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx ##:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "x=(1+\n",
    "  2+ #ops ##:\n",
    "  3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "# %reload_ext luri.cknoll_displaytools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "x=1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "#ahaa ##:\n",
    "x=1 ##:\n",
    "##:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x\n",
    "#aaaa ##:\n",
    "np.array([2,3]) ##:i\n",
    "2\n",
    "#bbbb\n",
    "'''\n",
    "3\n",
    "4\n",
    "'''\n",
    "3\n",
    "4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "x=1+1 ##:i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='x', start=(1, 0), end=(1, 1), line='x=1'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 1), end=(1, 2), line='x=1'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(1, 2), end=(1, 3), line='x=1'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 3), end=(1, 4), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"x=1\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=3 (STRING), string=\"'''x=1\\na\\nb\\nc'''\", start=(1, 0), end=(4, 4), line=\"'''x=1\\na\\nb\\nc'''\"),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(4, 4), end=(4, 5), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(5, 0), end=(5, 0), line='')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"'''x=1\\na\\nb\\nc'''\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='str', start=(1, 0), end=(1, 3), line=\"str='''x=1\\n\"),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 3), end=(1, 4), line=\"str='''x=1\\n\"),\n",
       " TokenInfo(type=3 (STRING), string=\"'''x=1\\na\\nb\\nc'''\", start=(1, 4), end=(4, 4), line=\"str='''x=1\\na\\nb\\nc'''\"),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(4, 4), end=(4, 5), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(5, 0), end=(5, 0), line='')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"str='''x=1\\na\\nb\\nc'''\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='x', start=(1, 0), end=(1, 1), line='x===1'),\n",
       " TokenInfo(type=53 (OP), string='==', start=(1, 1), end=(1, 3), line='x===1'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 3), end=(1, 4), line='x===1'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(1, 4), end=(1, 5), line='x===1'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 5), end=(1, 6), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"x===1\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='x', start=(1, 0), end=(1, 1), line='x===1\\n'),\n",
       " TokenInfo(type=53 (OP), string='==', start=(1, 1), end=(1, 3), line='x===1\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 3), end=(1, 4), line='x===1\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(1, 4), end=(1, 5), line='x===1\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 5), end=(1, 6), line='x===1\\n'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(2, 0), end=(2, 1), line='y=2'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(2, 1), end=(2, 2), line='y=2'),\n",
       " TokenInfo(type=2 (NUMBER), string='2', start=(2, 2), end=(2, 3), line='y=2'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(2, 3), end=(2, 4), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"x===1\\ny=2\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='def', start=(1, 0), end=(1, 3), line='def f(x):\\n'),\n",
       " TokenInfo(type=1 (NAME), string='f', start=(1, 4), end=(1, 5), line='def f(x):\\n'),\n",
       " TokenInfo(type=53 (OP), string='(', start=(1, 5), end=(1, 6), line='def f(x):\\n'),\n",
       " TokenInfo(type=1 (NAME), string='x', start=(1, 6), end=(1, 7), line='def f(x):\\n'),\n",
       " TokenInfo(type=53 (OP), string=')', start=(1, 7), end=(1, 8), line='def f(x):\\n'),\n",
       " TokenInfo(type=53 (OP), string=':', start=(1, 8), end=(1, 9), line='def f(x):\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 9), end=(1, 10), line='def f(x):\\n'),\n",
       " TokenInfo(type=5 (INDENT), string='  ', start=(2, 0), end=(2, 2), line='  y=1\\n'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(2, 2), end=(2, 3), line='  y=1\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(2, 3), end=(2, 4), line='  y=1\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(2, 4), end=(2, 5), line='  y=1\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(2, 5), end=(2, 6), line='  y=1\\n'),\n",
       " TokenInfo(type=1 (NAME), string='return', start=(3, 2), end=(3, 8), line='  return x+1'),\n",
       " TokenInfo(type=1 (NAME), string='x', start=(3, 9), end=(3, 10), line='  return x+1'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(3, 10), end=(3, 11), line='  return x+1'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(3, 11), end=(3, 12), line='  return x+1'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(3, 12), end=(3, 13), line=''),\n",
       " TokenInfo(type=6 (DEDENT), string='', start=(4, 0), end=(4, 0), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(4, 0), end=(4, 0), line='')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"def f(x):\\n  y=1\\n  return x+1\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=55 (COMMENT), string='#def f(x):', start=(1, 0), end=(1, 10), line='#def f(x):\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(1, 10), end=(1, 11), line='#def f(x):\\n'),\n",
       " TokenInfo(type=55 (COMMENT), string='#  return x+1', start=(2, 0), end=(2, 13), line='#  return x+1'),\n",
       " TokenInfo(type=56 (NL), string='', start=(2, 13), end=(2, 13), line='#  return x+1'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(2, 13), end=(2, 14), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(3, 0), end=(3, 0), line='')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"#def f(x):\\n#  return x+1\").readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='x', start=(1, 0), end=(1, 1), line='x=1'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 1), end=(1, 2), line='x=1'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(1, 2), end=(1, 3), line='x=1'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 3), end=(1, 4), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import tokenize as tk\n",
    "list( tk.generate_tokens(io.StringIO(\"x=1\").readline) ) #always gives a last empty token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "def str_to_tokens(string):\n",
    "    import io\n",
    "    import tokenize as tk\n",
    "    return list( tk.generate_tokens(io.StringIO(string).readline) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "def split_tokens(list_of_tokens):\n",
    "    \n",
    "    #obs to know how indented a block is gotta get ident -dedent number from previous\n",
    "    \n",
    "    import token\n",
    "    list_of_lists=[[]] #lol\n",
    "    list_of_indent_level=[0]\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    nlr=0 #round unquoted (OP)\n",
    "    nls=0 #square\n",
    "    nlc=0 #curly\n",
    "    \n",
    "    \n",
    "    current=1 #first line is 1 for some reason\n",
    "    j=-1\n",
    "    for tokenj in list_of_tokens:\n",
    "        j+=1\n",
    "        \n",
    "        if tokenj.start[0]>current: #first line is 1 for some reason\n",
    "            current = tokenj.end[0]\n",
    "            if nlr ==0 and nls==0 and nlc==0: #only advance if balanced\n",
    "                                    \n",
    "                #advance\n",
    "                i=i+1 #next list\n",
    "                list_of_lists+=[[]] #add a new list to our lol\n",
    "                if list_of_tokens[j].type==token.INDENT:\n",
    "                    list_of_indent_level += [ list_of_indent_level[-1]+1 ]\n",
    "                elif list_of_tokens[j].type==token.DEDENT:\n",
    "                    list_of_indent_level += [ list_of_indent_level[-1]-1 ]\n",
    "                else:\n",
    "                    list_of_indent_level += [ list_of_indent_level[-1] ]\n",
    "                    \n",
    "        \n",
    "        if tokenj.exact_type== token.LPAR:\n",
    "            nlr+=1\n",
    "        if tokenj.exact_type==token.LSQB:\n",
    "            nls+=1\n",
    "        if tokenj.exact_type==token.LBRACE:\n",
    "            nlc+=1\n",
    "        if tokenj.exact_type== token.RPAR:\n",
    "            nlr-=1\n",
    "        if tokenj.exact_type==token.RSQB:\n",
    "            nls-=1\n",
    "        if tokenj.exact_type==token.RBRACE:\n",
    "            nlc-=1\n",
    "        \n",
    "        if tokenj.type != token.ENDMARKER:\n",
    "            list_of_lists[i] += [tokenj] #add a new tokenj to the list_i\n",
    "\n",
    "    #finishing touches - trim trully empty lines\n",
    "    ntot = len(list_of_lists)\n",
    "    for i in range(ntot-1,-1,-1): #preserves lower indexes\n",
    "        #remove empty lists\n",
    "        if len(list_of_lists[i])==0:\n",
    "            del list_of_lists[i]\n",
    "        #remove solo \\n\n",
    "        elif len(list_of_lists[i])==1 and list_of_lists[i][0].string=='\\n':\n",
    "            del list_of_lists[i]\n",
    "        \n",
    "        \n",
    "    return list_of_lists, list_of_indent_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(9,-1,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[1,2,3]\n",
    "x.pop()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import token\n",
    "token.LPAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    }
   ],
   "source": [
    "celula='''1\n",
    "\n",
    "#comentario\n",
    "\n",
    "\n",
    "\"\"\"docs so\n",
    "\n",
    "confusin\n",
    "g\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "x=1 ##:\n",
    "\n",
    "y=(1+\n",
    "2+3+\n",
    "\n",
    "#one more\n",
    "\n",
    "4 #ok\n",
    ")\n",
    "\n",
    "z=1+\\\n",
    "2+\\\n",
    "\\\n",
    "\\\n",
    "4\n",
    "\n",
    "w=(\n",
    "\"A\"+\"\"\"\n",
    "B\n",
    "C\"\"\")\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    y=x+1 ##:\n",
    "    return y\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=2 (NUMBER), string='1', start=(1, 0), end=(1, 1), line='1\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 1), end=(1, 2), line='1\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(2, 0), end=(2, 1), line='\\n'),\n",
       " TokenInfo(type=55 (COMMENT), string='#comentario', start=(3, 0), end=(3, 11), line='#comentario\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(3, 11), end=(3, 12), line='#comentario\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(4, 0), end=(4, 1), line='\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(5, 0), end=(5, 1), line='\\n'),\n",
       " TokenInfo(type=3 (STRING), string='\"\"\"docs so\\n\\nconfusin\\ng\\n\"\"\"', start=(6, 0), end=(10, 3), line='\"\"\"docs so\\n\\nconfusin\\ng\\n\"\"\"\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(10, 3), end=(10, 4), line='\"\"\"\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(11, 0), end=(11, 1), line='\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(12, 0), end=(12, 1), line='\\n'),\n",
       " TokenInfo(type=1 (NAME), string='x', start=(13, 0), end=(13, 1), line='x=1 ##:\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(13, 1), end=(13, 2), line='x=1 ##:\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(13, 2), end=(13, 3), line='x=1 ##:\\n'),\n",
       " TokenInfo(type=55 (COMMENT), string='##:', start=(13, 4), end=(13, 7), line='x=1 ##:\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(13, 7), end=(13, 8), line='x=1 ##:\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(14, 0), end=(14, 1), line='\\n'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(15, 0), end=(15, 1), line='y=(1+\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(15, 1), end=(15, 2), line='y=(1+\\n'),\n",
       " TokenInfo(type=53 (OP), string='(', start=(15, 2), end=(15, 3), line='y=(1+\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(15, 3), end=(15, 4), line='y=(1+\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(15, 4), end=(15, 5), line='y=(1+\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(15, 5), end=(15, 6), line='y=(1+\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='2', start=(16, 0), end=(16, 1), line='2+3+\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(16, 1), end=(16, 2), line='2+3+\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='3', start=(16, 2), end=(16, 3), line='2+3+\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(16, 3), end=(16, 4), line='2+3+\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(16, 4), end=(16, 5), line='2+3+\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(17, 0), end=(17, 1), line='\\n'),\n",
       " TokenInfo(type=55 (COMMENT), string='#one more', start=(18, 0), end=(18, 9), line='#one more\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(18, 9), end=(18, 10), line='#one more\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(19, 0), end=(19, 1), line='\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='4', start=(20, 0), end=(20, 1), line='4 #ok\\n'),\n",
       " TokenInfo(type=55 (COMMENT), string='#ok', start=(20, 2), end=(20, 5), line='4 #ok\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(20, 5), end=(20, 6), line='4 #ok\\n'),\n",
       " TokenInfo(type=53 (OP), string=')', start=(21, 0), end=(21, 1), line=')\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(21, 1), end=(21, 2), line=')\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(22, 0), end=(22, 1), line='\\n'),\n",
       " TokenInfo(type=1 (NAME), string='z', start=(23, 0), end=(23, 1), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(23, 1), end=(23, 2), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(23, 2), end=(23, 3), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(23, 3), end=(23, 4), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='2', start=(23, 4), end=(23, 5), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(23, 5), end=(23, 6), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='4', start=(23, 6), end=(23, 7), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(23, 7), end=(23, 8), line='z=1+2+4\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(24, 0), end=(24, 1), line='\\n'),\n",
       " TokenInfo(type=1 (NAME), string='w', start=(25, 0), end=(25, 1), line='w=(\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(25, 1), end=(25, 2), line='w=(\\n'),\n",
       " TokenInfo(type=53 (OP), string='(', start=(25, 2), end=(25, 3), line='w=(\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(25, 3), end=(25, 4), line='w=(\\n'),\n",
       " TokenInfo(type=3 (STRING), string='\"A\"', start=(26, 0), end=(26, 3), line='\"A\"+\"\"\"\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(26, 3), end=(26, 4), line='\"A\"+\"\"\"\\n'),\n",
       " TokenInfo(type=3 (STRING), string='\"\"\"\\nB\\nC\"\"\"', start=(26, 4), end=(28, 4), line='\"A\"+\"\"\"\\nB\\nC\"\"\")\\n'),\n",
       " TokenInfo(type=53 (OP), string=')', start=(28, 4), end=(28, 5), line='C\"\"\")\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(28, 5), end=(28, 6), line='C\"\"\")\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(29, 0), end=(29, 1), line='\\n'),\n",
       " TokenInfo(type=56 (NL), string='\\n', start=(30, 0), end=(30, 1), line='\\n'),\n",
       " TokenInfo(type=1 (NAME), string='def', start=(31, 0), end=(31, 3), line='def f(x):\\n'),\n",
       " TokenInfo(type=1 (NAME), string='f', start=(31, 4), end=(31, 5), line='def f(x):\\n'),\n",
       " TokenInfo(type=53 (OP), string='(', start=(31, 5), end=(31, 6), line='def f(x):\\n'),\n",
       " TokenInfo(type=1 (NAME), string='x', start=(31, 6), end=(31, 7), line='def f(x):\\n'),\n",
       " TokenInfo(type=53 (OP), string=')', start=(31, 7), end=(31, 8), line='def f(x):\\n'),\n",
       " TokenInfo(type=53 (OP), string=':', start=(31, 8), end=(31, 9), line='def f(x):\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(31, 9), end=(31, 10), line='def f(x):\\n'),\n",
       " TokenInfo(type=5 (INDENT), string='    ', start=(32, 0), end=(32, 4), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(32, 4), end=(32, 5), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(32, 5), end=(32, 6), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=1 (NAME), string='x', start=(32, 6), end=(32, 7), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=53 (OP), string='+', start=(32, 7), end=(32, 8), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(32, 8), end=(32, 9), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=55 (COMMENT), string='##:', start=(32, 10), end=(32, 13), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(32, 13), end=(32, 14), line='    y=x+1 ##:\\n'),\n",
       " TokenInfo(type=1 (NAME), string='return', start=(33, 4), end=(33, 10), line='    return y\\n'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(33, 11), end=(33, 12), line='    return y\\n'),\n",
       " TokenInfo(type=4 (NEWLINE), string='\\n', start=(33, 12), end=(33, 13), line='    return y\\n'),\n",
       " TokenInfo(type=6 (DEDENT), string='', start=(34, 0), end=(34, 0), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(34, 0), end=(34, 0), line='')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_tokens(celula)\n",
    "#newline means a line ended\n",
    "\n",
    "#nl means a comment line ended . either pure or a statement line with comment in the end\n",
    "\n",
    "#nl means a line is empty\n",
    "\n",
    "#multiline strings are a string+newline\n",
    "\n",
    "#nl sometimes means an empty line inside continued expression with unmatched brackets\n",
    "#cannot place arbitrary displays lines there!\n",
    "\n",
    "#lines continued with \\ do not get newlines or nls in the tokenization nor update in line number in start tuple\n",
    "\n",
    "#conclusion: split tokens in sections after NL or NEWLINES but keep those in unmatched braces together (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('PLUS', 'LPAR', 'OP')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.tok_name[14], tokenize.tok_name[7], tokenize.tok_name[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n",
      "0 ENDMARKER\n",
      "1 NAME\n",
      "2 NUMBER\n",
      "3 STRING\n",
      "4 NEWLINE\n",
      "5 INDENT\n",
      "6 DEDENT\n",
      "7 LPAR\n",
      "8 RPAR\n",
      "9 LSQB\n",
      "10 RSQB\n",
      "11 COLON\n",
      "12 COMMA\n",
      "13 SEMI\n",
      "14 PLUS\n",
      "15 MINUS\n",
      "16 STAR\n",
      "17 SLASH\n",
      "18 VBAR\n",
      "19 AMPER\n",
      "20 LESS\n",
      "21 GREATER\n",
      "22 EQUAL\n",
      "23 DOT\n",
      "24 PERCENT\n",
      "25 LBRACE\n",
      "26 RBRACE\n",
      "27 EQEQUAL\n",
      "28 NOTEQUAL\n",
      "29 LESSEQUAL\n",
      "30 GREATEREQUAL\n",
      "31 TILDE\n",
      "32 CIRCUMFLEX\n",
      "33 LEFTSHIFT\n",
      "34 RIGHTSHIFT\n",
      "35 DOUBLESTAR\n",
      "36 PLUSEQUAL\n",
      "37 MINEQUAL\n",
      "38 STAREQUAL\n",
      "39 SLASHEQUAL\n",
      "40 PERCENTEQUAL\n",
      "41 AMPEREQUAL\n",
      "42 VBAREQUAL\n",
      "43 CIRCUMFLEXEQUAL\n",
      "44 LEFTSHIFTEQUAL\n",
      "45 RIGHTSHIFTEQUAL\n",
      "46 DOUBLESTAREQUAL\n",
      "47 DOUBLESLASH\n",
      "48 DOUBLESLASHEQUAL\n",
      "49 AT\n",
      "50 ATEQUAL\n",
      "51 RARROW\n",
      "52 ELLIPSIS\n",
      "53 OP\n",
      "54 ERRORTOKEN\n",
      "55 COMMENT\n",
      "56 NL\n",
      "57 ENCODING\n",
      "58 N_TOKENS\n"
     ]
    }
   ],
   "source": [
    "import tokenize\n",
    "for i in range(100):\n",
    "    try:\n",
    "        print(i, tokenize.tok_name[i])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n",
      "11\n",
      "--\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(1, 0), end=(1, 1), line='1\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(1, 1), end=(1, 2), line='1\\n')\n",
      "--\n",
      "TokenInfo(type=55 (COMMENT), string='#comentario', start=(3, 0), end=(3, 11), line='#comentario\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(3, 11), end=(3, 12), line='#comentario\\n')\n",
      "--\n",
      "TokenInfo(type=3 (STRING), string='\"\"\"docs so\\n\\nconfusin\\ng\\n\"\"\"', start=(6, 0), end=(10, 3), line='\"\"\"docs so\\n\\nconfusin\\ng\\n\"\"\"\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(10, 3), end=(10, 4), line='\"\"\"\\n')\n",
      "--\n",
      "TokenInfo(type=1 (NAME), string='x', start=(13, 0), end=(13, 1), line='x=1 ##:\\n')\n",
      "TokenInfo(type=53 (OP), string='=', start=(13, 1), end=(13, 2), line='x=1 ##:\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(13, 2), end=(13, 3), line='x=1 ##:\\n')\n",
      "TokenInfo(type=55 (COMMENT), string='##:', start=(13, 4), end=(13, 7), line='x=1 ##:\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(13, 7), end=(13, 8), line='x=1 ##:\\n')\n",
      "--\n",
      "TokenInfo(type=1 (NAME), string='y', start=(15, 0), end=(15, 1), line='y=(1+\\n')\n",
      "TokenInfo(type=53 (OP), string='=', start=(15, 1), end=(15, 2), line='y=(1+\\n')\n",
      "TokenInfo(type=53 (OP), string='(', start=(15, 2), end=(15, 3), line='y=(1+\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(15, 3), end=(15, 4), line='y=(1+\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(15, 4), end=(15, 5), line='y=(1+\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(15, 5), end=(15, 6), line='y=(1+\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='2', start=(16, 0), end=(16, 1), line='2+3+\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(16, 1), end=(16, 2), line='2+3+\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='3', start=(16, 2), end=(16, 3), line='2+3+\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(16, 3), end=(16, 4), line='2+3+\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(16, 4), end=(16, 5), line='2+3+\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(17, 0), end=(17, 1), line='\\n')\n",
      "TokenInfo(type=55 (COMMENT), string='#one more', start=(18, 0), end=(18, 9), line='#one more\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(18, 9), end=(18, 10), line='#one more\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(19, 0), end=(19, 1), line='\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='4', start=(20, 0), end=(20, 1), line='4 #ok\\n')\n",
      "TokenInfo(type=55 (COMMENT), string='#ok', start=(20, 2), end=(20, 5), line='4 #ok\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(20, 5), end=(20, 6), line='4 #ok\\n')\n",
      "TokenInfo(type=53 (OP), string=')', start=(21, 0), end=(21, 1), line=')\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(21, 1), end=(21, 2), line=')\\n')\n",
      "--\n",
      "TokenInfo(type=1 (NAME), string='z', start=(23, 0), end=(23, 1), line='z=1+2+4\\n')\n",
      "TokenInfo(type=53 (OP), string='=', start=(23, 1), end=(23, 2), line='z=1+2+4\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(23, 2), end=(23, 3), line='z=1+2+4\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(23, 3), end=(23, 4), line='z=1+2+4\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='2', start=(23, 4), end=(23, 5), line='z=1+2+4\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(23, 5), end=(23, 6), line='z=1+2+4\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='4', start=(23, 6), end=(23, 7), line='z=1+2+4\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(23, 7), end=(23, 8), line='z=1+2+4\\n')\n",
      "--\n",
      "TokenInfo(type=1 (NAME), string='w', start=(25, 0), end=(25, 1), line='w=(\\n')\n",
      "TokenInfo(type=53 (OP), string='=', start=(25, 1), end=(25, 2), line='w=(\\n')\n",
      "TokenInfo(type=53 (OP), string='(', start=(25, 2), end=(25, 3), line='w=(\\n')\n",
      "TokenInfo(type=56 (NL), string='\\n', start=(25, 3), end=(25, 4), line='w=(\\n')\n",
      "TokenInfo(type=3 (STRING), string='\"A\"', start=(26, 0), end=(26, 3), line='\"A\"+\"\"\"\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(26, 3), end=(26, 4), line='\"A\"+\"\"\"\\n')\n",
      "TokenInfo(type=3 (STRING), string='\"\"\"\\nB\\nC\"\"\"', start=(26, 4), end=(28, 4), line='\"A\"+\"\"\"\\nB\\nC\"\"\")\\n')\n",
      "TokenInfo(type=53 (OP), string=')', start=(28, 4), end=(28, 5), line='C\"\"\")\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(28, 5), end=(28, 6), line='C\"\"\")\\n')\n",
      "--\n",
      "TokenInfo(type=1 (NAME), string='def', start=(31, 0), end=(31, 3), line='def f(x):\\n')\n",
      "TokenInfo(type=1 (NAME), string='f', start=(31, 4), end=(31, 5), line='def f(x):\\n')\n",
      "TokenInfo(type=53 (OP), string='(', start=(31, 5), end=(31, 6), line='def f(x):\\n')\n",
      "TokenInfo(type=1 (NAME), string='x', start=(31, 6), end=(31, 7), line='def f(x):\\n')\n",
      "TokenInfo(type=53 (OP), string=')', start=(31, 7), end=(31, 8), line='def f(x):\\n')\n",
      "TokenInfo(type=53 (OP), string=':', start=(31, 8), end=(31, 9), line='def f(x):\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(31, 9), end=(31, 10), line='def f(x):\\n')\n",
      "--\n",
      "TokenInfo(type=5 (INDENT), string='    ', start=(32, 0), end=(32, 4), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=1 (NAME), string='y', start=(32, 4), end=(32, 5), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=53 (OP), string='=', start=(32, 5), end=(32, 6), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=1 (NAME), string='x', start=(32, 6), end=(32, 7), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=53 (OP), string='+', start=(32, 7), end=(32, 8), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(32, 8), end=(32, 9), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=55 (COMMENT), string='##:', start=(32, 10), end=(32, 13), line='    y=x+1 ##:\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(32, 13), end=(32, 14), line='    y=x+1 ##:\\n')\n",
      "--\n",
      "TokenInfo(type=1 (NAME), string='return', start=(33, 4), end=(33, 10), line='    return y\\n')\n",
      "TokenInfo(type=1 (NAME), string='y', start=(33, 11), end=(33, 12), line='    return y\\n')\n",
      "TokenInfo(type=4 (NEWLINE), string='\\n', start=(33, 12), end=(33, 13), line='    return y\\n')\n",
      "--\n",
      "TokenInfo(type=6 (DEDENT), string='', start=(34, 0), end=(34, 0), line='')\n"
     ]
    }
   ],
   "source": [
    "test,test2 = split_tokens(str_to_tokens(celula))\n",
    "print(len(test))\n",
    "for testei in test:\n",
    "    print('--')\n",
    "    for testeij in testei:\n",
    "        print(testeij) #, print(testeij.exact_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1x2x3'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'x'.join(['1','2','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n",
      "1 \n",
      "\n",
      "#comentario \n",
      "\n",
      "\"\"\"docs so\n",
      "\n",
      "confusin\n",
      "g\n",
      "\"\"\" \n",
      "\n",
      "x = 1 ##: \n",
      "\n",
      "print( '( x ) = ', x )\n",
      "y = ( 1 + \n",
      " 2 + 3 + \n",
      " \n",
      " #one more \n",
      " \n",
      " 4 #ok \n",
      " ) \n",
      "\n",
      "z = 1 + 2 + 4 \n",
      "\n",
      "w = ( \n",
      " \"A\" + \"\"\"\n",
      "B\n",
      "C\"\"\" ) \n",
      "\n",
      "def f ( x ) : \n",
      "\n",
      "    y = x + 1 ##: \n",
      "\n",
      "    print( '( y ) = ', y )\n",
      "    return y \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def recreate(lol):\n",
    "    string2=''\n",
    "    nindent=0\n",
    "    strindent=\"    \"\n",
    "    for li in lol:\n",
    "#         for lij in li:\n",
    "\n",
    "        #plain recreate\n",
    "\n",
    "        \n",
    "        if li[0].type == token.INDENT:\n",
    "            nindent+=1\n",
    "            string2 += nindent*\"    \" + ' '.join([lij.string for lij in li[1:]]) +\"\\n\" #add an extra nl for free\n",
    "        elif li[0].type == token.DEDENT:\n",
    "            nindent-=1\n",
    "            string2 += nindent*\"    \" + ' '.join([lij.string for lij in li[1:]]) +\"\\n\" #add an extra nl for free\n",
    "        else:\n",
    "            string2 += nindent*\"    \" + ' '.join([lij.string for lij in li]) +\"\\n\" #add an extra nl for free\n",
    "        \n",
    "        #process\n",
    "        procthisblock=False\n",
    "        \n",
    "        #insert\n",
    "        \n",
    "        #x=1\n",
    "        #find ##:\n",
    "        for lij in li:\n",
    "#             print(\">>>\",lij.string)\n",
    "            if lij.type==token.COMMENT and \"##:\" in lij.string:\n",
    "#               print(\"aí tem\")\n",
    "                procthisblock=True\n",
    "        if procthisblock:\n",
    "            \n",
    "\n",
    "            \n",
    "            equalthisblock=0\n",
    "            for k,lij in enumerate(li):\n",
    "    #             print(\">>>\",lij.string)\n",
    "                if lij.exact_type==token.EQUAL:\n",
    "#                     print('>>>',li[k-1].string,'<<<','=','>>>',li[k+1].string,'<<<',)\n",
    "                    equalthisblock=k #integer where the equal is\n",
    "        \n",
    "            if equalthisblock != 0:\n",
    "                string2+=nindent*\"    \" + \"print( \"+ \"'( \"+li[equalthisblock-1].string+\" ) = ', \"+  li[equalthisblock-1].string + \" )\"+'\\n'\n",
    "                equalthisblock=0\n",
    "        \n",
    "        procthisblock=False\n",
    "        #find =\n",
    "        #find x\n",
    "        #find 1\n",
    "        \n",
    "    return string2\n",
    "string2=recreate(test)\n",
    "print(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxx2 override function to run each cell\n",
      "( x ) =  1\n",
      "( y ) =  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 \n",
    "\n",
    "#comentario \n",
    "\n",
    "\"\"\"docs so\n",
    "\n",
    "confusin\n",
    "g\n",
    "\"\"\" \n",
    "\n",
    "x = 1 ##: \n",
    "\n",
    "print( '( x ) = ', x )\n",
    "y = ( 1 + \n",
    " 2 + 3 + \n",
    " \n",
    " #one more \n",
    " \n",
    " 4 #ok \n",
    " ) \n",
    "\n",
    "z = 1 + 2 + 4 \n",
    "\n",
    "w = ( \n",
    " \"A\" + \"\"\"\n",
    "B\n",
    "C\"\"\" ) \n",
    "\n",
    "def f ( x ) : \n",
    "\n",
    "    y = x + 1 ##: \n",
    "\n",
    "    print( '( y ) = ', y )\n",
    "    return y\n",
    "\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[\n",
    "    \n",
    "    \n",
    "    \n",
    "    2,3]\n",
    "x=y[0\n",
    "    \n",
    "    \n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='x', start=(1, 0), end=(1, 1), line='x=y[1]'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 1), end=(1, 2), line='x=y[1]'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(1, 2), end=(1, 3), line='x=y[1]'),\n",
       " TokenInfo(type=53 (OP), string='[', start=(1, 3), end=(1, 4), line='x=y[1]'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(1, 4), end=(1, 5), line='x=y[1]'),\n",
       " TokenInfo(type=53 (OP), string=']', start=(1, 5), end=(1, 6), line='x=y[1]'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 6), end=(1, 7), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_tokens('x=y[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='x', start=(1, 0), end=(1, 1), line='x=y[1]'),\n",
       " TokenInfo(type=53 (OP), string='=', start=(1, 1), end=(1, 2), line='x=y[1]'),\n",
       " TokenInfo(type=1 (NAME), string='y', start=(1, 2), end=(1, 3), line='x=y[1]'),\n",
       " TokenInfo(type=53 (OP), string='[', start=(1, 3), end=(1, 4), line='x=y[1]'),\n",
       " TokenInfo(type=2 (NUMBER), string='1', start=(1, 4), end=(1, 5), line='x=y[1]'),\n",
       " TokenInfo(type=53 (OP), string=']', start=(1, 5), end=(1, 6), line='x=y[1]'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 6), end=(1, 7), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_tokens('x=y[1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '',\n",
       " '#comentario',\n",
       " '',\n",
       " '',\n",
       " '\"\"\"docs so',\n",
       " '',\n",
       " 'confusin',\n",
       " 'g',\n",
       " '\"\"\"',\n",
       " '',\n",
       " '',\n",
       " 'x=1 ##:',\n",
       " '',\n",
       " 'y=(1+',\n",
       " '2+3+',\n",
       " '',\n",
       " '#one more',\n",
       " '',\n",
       " '4 #ok',\n",
       " ')',\n",
       " '',\n",
       " 'z=1+2+4',\n",
       " '',\n",
       " 'w=(',\n",
       " '\"A\"+\"\"\"',\n",
       " 'B',\n",
       " 'C\"\"\")',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celula.split('\\n') #if tokenize 1st then multiline stick together\n",
    "#(notice start and end have different line ints in start and end tuple)\n",
    "#if split first then all falls apart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newcell(string1):\n",
    "    #string1 is old cell content\n",
    "    \n",
    "    #split cell into lines\n",
    "    lines=string1.split('\\n')\n",
    "    \n",
    "    #string2 is the new cell content\n",
    "    string2=\"\"\n",
    "    for linei in lines:\n",
    "        print()\n",
    "        \n",
    "        #tokenize 1 line\n",
    "        tokensi=str_to_tokens(linei)\n",
    "        \n",
    "#         for tokenij in tokensi: #debug\n",
    "#             print(tokenij) #debug\n",
    "        \n",
    "        #remove useless tokens\n",
    "        if tokensi[-1].type==0: #endmarker\n",
    "            del tokensi[-1]\n",
    "            \n",
    "        #remove useless tokens\n",
    "        if len(tokensi)>=1:\n",
    "            if tokensi[-1].type==4: #newline\n",
    "                del tokensi[-1]\n",
    "\n",
    "        for tokenij in tokensi: #debug\n",
    "            print(tokenij) #debug                \n",
    "                \n",
    "        string2 += \" \".join( [tokenij.string for tokenij in tokensi] )+'\\n'\n",
    "    return string2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TokenInfo(type=2 (NUMBER), string='1', start=(1, 0), end=(1, 1), line='1')\n",
      "\n",
      "\n",
      "TokenInfo(type=55 (COMMENT), string='#comentario', start=(1, 0), end=(1, 11), line='#comentario')\n",
      "TokenInfo(type=56 (NL), string='', start=(1, 11), end=(1, 11), line='#comentario')\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TokenError",
     "evalue": "('EOF in multi-line string', (1, 0))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTokenError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8029ed9e2c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnovaceluala\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcelula\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnovaceluala\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-b321667b4b3f>\u001b[0m in \u001b[0;36mnewcell\u001b[0;34m(string1)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#tokenize 1 line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtokensi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr_to_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinei\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#         for tokenij in tokensi: #debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-794b4fd4df25>\u001b[0m in \u001b[0;36mstr_to_tokens\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontstr\u001b[0m\u001b[0;34m:\u001b[0m                            \u001b[0;31m# continued string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTokenError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"EOF in multi-line string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0mendmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mendmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTokenError\u001b[0m: ('EOF in multi-line string', (1, 0))"
     ]
    }
   ],
   "source": [
    "novaceluala=newcell(celula)\n",
    "print('---')\n",
    "print(novaceluala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=3 (STRING), string='\"\"\"a or b ##:\\n              \\n              \"\"\"', start=(1, 0), end=(3, 17), line='\"\"\"a or b ##:\\n              \\n              \"\"\"'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(3, 17), end=(3, 18), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(4, 0), end=(4, 0), line='')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_tokens('''\"\"\"a or b ##:\n",
    "              \n",
    "              \"\"\"''') #does a multiline string come as one string in the token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenInfo(type=1 (NAME), string='a', start=(1, 0), end=(1, 1), line='a or b ##:'),\n",
       " TokenInfo(type=1 (NAME), string='or', start=(1, 2), end=(1, 4), line='a or b ##:'),\n",
       " TokenInfo(type=1 (NAME), string='b', start=(1, 5), end=(1, 6), line='a or b ##:'),\n",
       " TokenInfo(type=55 (COMMENT), string='##:', start=(1, 7), end=(1, 10), line='a or b ##:'),\n",
       " TokenInfo(type=4 (NEWLINE), string='', start=(1, 10), end=(1, 11), line=''),\n",
       " TokenInfo(type=0 (ENDMARKER), string='', start=(2, 0), end=(2, 0), line='')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_to_tokens('a or b ##:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"##:\" in \"testandoooo ##: testeeeeeee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
